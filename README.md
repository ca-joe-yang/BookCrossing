Book Crossing
===
- https://learner.csie.ntu.edu.tw/judge/ml18spring/track1/

# Errors
- "02e87fe603,014028009,8", "02e87fe603,014028009X,8"
- Books ISBN
    + Books in "book_ratings_train.csv" but not in "books.csv": 23262
    + Books in "book_ratings_test.csv" but not in "books.csv": 16307
    + Books in "implicit_ratings.csv" but not in "books.csv": 44925

# Requirements
- wget

# Inputs
- User
    + Location (City / State / Country)
    + Age
- Book
    + ISBN
    + Title
    + Authors
    + Year
    + Publisher
    + Image
    + Description

# Outpus
- Rating: 0 ~ 10

# Methods

## CF: Collaborating Filtering


### Baseline

#### Training
```text
1: 260200/260200, loss:1.457
2: 260200/260200, loss:1.398
3: 260200/260200, loss:1.357
4: 260200/260200, loss:1.325
5: 260200/260200, loss:1.298
6: 260200/260200, loss:1.275
7: 260200/260200, loss:1.254
8: 260200/260200, loss:1.236
9: 260200/260200, loss:1.218
10: 260200/260200, loss:1.203
11: 260200/260200, loss:1.188
12: 260200/260200, loss:1.174
13: 260200/260200, loss:1.161
14: 260200/260200, loss:1.149
15: 260200/260200, loss:1.137
16: 260200/260200, loss:1.126
17: 260200/260200, loss:1.116
18: 260200/260200, loss:1.106
19: 260200/260200, loss:1.096
20: 260200/260200, loss:1.087
21: 260200/260200, loss:1.078
22: 260200/260200, loss:1.069
23: 260200/260200, loss:1.061
24: 260200/260200, loss:1.053
25: 260200/260200, loss:1.045
26: 260200/260200, loss:1.037
27: 260200/260200, loss:1.030
28: 260200/260200, loss:1.022
29: 260200/260200, loss:1.016
30: 260200/260200, loss:1.009
31: 260200/260200, loss:1.002
32: 260200/260200, loss:0.996
33: 260200/260200, loss:0.990
34: 260200/260200, loss:0.984
35: 260200/260200, loss:0.978
36: 260200/260200, loss:0.972
37: 260200/260200, loss:0.966
38: 260200/260200, loss:0.961
39: 260200/260200, loss:0.955
40: 260200/260200, loss:0.950
```

### Latent

#### Training
```text
1: 260200/260200, loss:1.429
2: 260200/260200, loss:1.371
3: 260200/260200, loss:1.332
4: 205136/260200, loss:1.300
4: 260200/260200, loss:1.300
5: 260200/260200, loss:1.273
6: 260200/260200, loss:1.248
7: 260200/260200, loss:1.226
8: 260200/260200, loss:1.205
9: 260200/260200, loss:1.185
10: 260200/260200, loss:1.166
11: 260200/260200, loss:1.148
12: 260200/260200, loss:1.130
13: 260200/260200, loss:1.113
14: 260200/260200, loss:1.097
15: 260200/260200, loss:1.083
16: 260200/260200, loss:1.069
17: 260200/260200, loss:1.055
18: 260200/260200, loss:1.042
19: 260200/260200, loss:1.030
20: 260200/260200, loss:1.017
```


# epoch 15
epoch 15
epoch 15
    1.306346
    loss: mae
    lambda=0 